{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Stock Market Analyzer\n",
    "Actual trading scripts will be later implemented (potentially through a seperate program). As of right now, this program just aims to predict future prices.\n",
    "\n",
    "Potential Limitations/Bottlenecks: Yahoo API support for small intervals & rate limiting for large datasets\n",
    "\n",
    "#### Necessary Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Data Collection -- \n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "\n",
    "# -- Data Cleaning & Preparation --\n",
    "#//Necessary Libraries Here, will add as needed\n",
    "\n",
    "# -- Shallow ML Models --\n",
    "\n",
    "# Testing Accuracy\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "# Simple Linear Regression (Predicting Values)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# SGD Regression (Predicting Values)\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "# Ridge Regression (Predicting Values, assuming <100k samples)\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "# SVR Regression (Predicting Values, kernel dependant on sample size)\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# SGD Classifier (Classifying movement, assuming >100k samples)\n",
    "from sklearn.linear_model import SGDClassifier #(Be careful with feature scaling)\n",
    "\n",
    "# Kernel Approximation (Classifying movement, assuming >100k samples)\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.kernel_approximation import PolynomialCountSketch #*\n",
    "\n",
    "# Linear SVC (Classifying movement, assuming <100k samples)\n",
    "from sklearn import svm\n",
    "\n",
    "# KNeighbors Classification (Classifying Movement, assuming <100k samples)\n",
    "from sklearn.neighbors import KNeighborsClassifier #Could also add regressor\n",
    "\n",
    "#Decision Trees (Predicting Price & Classifying Movement, Good Visual)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# -- Deep ML Model --\n",
    "#Will utilize tensorflow, will need to learn more about first\n",
    "#Recurrent Neural Network & Convolutional Neural Network Hybrid\n",
    "#Temporal Convolutional Networks\n",
    "#Long Short-Term Memory Networks (Little Data)\n",
    "#Gated Recurrent Unit (GRU) Networks (More Data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Open        High         Low       Close  \\\n",
      "Date                                                                        \n",
      "1980-12-12 00:00:00-05:00    0.099192    0.099623    0.099192    0.099192   \n",
      "1980-12-15 00:00:00-05:00    0.094448    0.094448    0.094017    0.094017   \n",
      "1980-12-16 00:00:00-05:00    0.087548    0.087548    0.087117    0.087117   \n",
      "1980-12-17 00:00:00-05:00    0.089273    0.089704    0.089273    0.089273   \n",
      "1980-12-18 00:00:00-05:00    0.091861    0.092292    0.091861    0.091861   \n",
      "...                               ...         ...         ...         ...   \n",
      "2024-06-07 00:00:00-04:00  194.649994  196.940002  194.139999  196.889999   \n",
      "2024-06-10 00:00:00-04:00  196.899994  197.300003  192.149994  193.119995   \n",
      "2024-06-11 00:00:00-04:00  193.649994  207.160004  193.630005  207.149994   \n",
      "2024-06-12 00:00:00-04:00  207.369995  220.199997  206.899994  213.070007   \n",
      "2024-06-13 00:00:00-04:00  214.779999  216.750000  211.600006  214.240005   \n",
      "\n",
      "                              Volume  \n",
      "Date                                  \n",
      "1980-12-12 00:00:00-05:00  469033600  \n",
      "1980-12-15 00:00:00-05:00  175884800  \n",
      "1980-12-16 00:00:00-05:00  105728000  \n",
      "1980-12-17 00:00:00-05:00   86441600  \n",
      "1980-12-18 00:00:00-05:00   73449600  \n",
      "...                              ...  \n",
      "2024-06-07 00:00:00-04:00   53103900  \n",
      "2024-06-10 00:00:00-04:00   97262100  \n",
      "2024-06-11 00:00:00-04:00  172373300  \n",
      "2024-06-12 00:00:00-04:00  198134300  \n",
      "2024-06-13 00:00:00-04:00   96416123  \n",
      "\n",
      "[10967 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "ticker_symbol = 'AAPL' #Placeholder for now\n",
    "t_period = \"max\" #Time Period to test, For testing purposes\n",
    "t_interval = \"1d\" #Intervals to collect data for, For testing purposes\n",
    "\n",
    "ticker = yf.Ticker(ticker_symbol)\n",
    "historical_data = ticker.history(period=t_period, interval=t_interval, actions=False, auto_adjust=True)\n",
    "print(historical_data) #Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformatting the Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifting to include previous high, previous low, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             open   prev_high    prev_low  prev_volume        Close  \\\n",
      "1        0.094448    0.099623    0.099192     0.099192  175884800.0   \n",
      "2        0.087548    0.094448    0.094017     0.094017  105728000.0   \n",
      "3        0.089273    0.087548    0.087117     0.087117   86441600.0   \n",
      "4        0.091861    0.089704    0.089273     0.089273   73449600.0   \n",
      "5        0.097467    0.092292    0.091861     0.091861   48630400.0   \n",
      "...           ...         ...         ...          ...          ...   \n",
      "10962  194.649994  196.500000  194.169998   194.479996   53103900.0   \n",
      "10963  196.899994  196.940002  194.139999   196.889999   97262100.0   \n",
      "10964  193.649994  197.300003  192.149994   193.119995  172373300.0   \n",
      "10965  207.369995  207.160004  193.630005   207.149994  198134300.0   \n",
      "10966  214.779999  220.199997  206.899994   213.070007   96416123.0   \n",
      "\n",
      "        prev_open  prev_close  \n",
      "1        0.099192    0.099192  \n",
      "2        0.094448    0.094017  \n",
      "3        0.087548    0.087117  \n",
      "4        0.089273    0.089273  \n",
      "5        0.091861    0.091861  \n",
      "...           ...         ...  \n",
      "10962  195.690002  194.479996  \n",
      "10963  194.649994  196.889999  \n",
      "10964  196.899994  193.119995  \n",
      "10965  193.649994  207.149994  \n",
      "10966  207.369995  213.070007  \n",
      "\n",
      "[10966 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "if len(historical_data.columns) == 5:\n",
    "    # Renaming Columns \n",
    "    historical_data['prev_open'] = historical_data['Open']\n",
    "    historical_data['prev_close'] = historical_data['Close']\n",
    "    historical_data.columns = ['open', 'prev_high', 'prev_low', 'prev_volume', 'Close', 'prev_open', 'prev_close']\n",
    "\n",
    "    #Creating a dummy row for shifting\n",
    "    empty_row = pd.DataFrame([None] * len(historical_data.columns)).T #Creating an empty row to concatonate\n",
    "    empty_row.columns = historical_data.columns\n",
    "    historical_data = pd.concat([historical_data, empty_row], ignore_index=True)\n",
    "    \n",
    "    #Shifting down all statistics for previous days\n",
    "    historical_data['prev_high'] = historical_data['prev_high'].shift(1)\n",
    "    historical_data['prev_low'] = historical_data['prev_low'].shift(1)\n",
    "    historical_data['prev_close'] = historical_data['prev_close'].shift(1)\n",
    "    historical_data['prev_volume'] = historical_data['prev_volume'].shift(1)\n",
    "    historical_data['prev_open'] = historical_data['prev_open'].shift(1)\n",
    "    \n",
    "    #Creating a new df with the most recent statistics\n",
    "    most_recent = historical_data.iloc[-1:].copy()\n",
    "    #Replacing unknown statistics with signal value\n",
    "    most_recent.iloc[-1, most_recent.columns.get_loc('open')] = 999999\n",
    "    most_recent.iloc[-1, most_recent.columns.get_loc('Close')] = 999999\n",
    "    \n",
    "    \n",
    "    #Dropping all empty columns\n",
    "    historical_data.replace(['NA', 'NaN', None], np.nan, inplace=True)\n",
    "    historical_data = historical_data.dropna()\n",
    "    \n",
    "\n",
    "print(historical_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to numpy array for increased efficiency. Although most models do this internally anyways, explicitly converting can reduce overhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.44484613e-02 9.96233438e-02 9.91920978e-02 9.91920978e-02\n",
      "  9.91920978e-02 9.91920978e-02]\n",
      " [8.75477574e-02 9.44484613e-02 9.40172151e-02 9.40172151e-02\n",
      "  9.44484613e-02 9.40172151e-02]\n",
      " [8.92727226e-02 8.75477574e-02 8.71165171e-02 8.71165171e-02\n",
      "  8.75477574e-02 8.71165171e-02]\n",
      " ...\n",
      " [1.93649994e+02 1.97300003e+02 1.92149994e+02 1.93119995e+02\n",
      "  1.96899994e+02 1.93119995e+02]\n",
      " [2.07369995e+02 2.07160004e+02 1.93630005e+02 2.07149994e+02\n",
      "  1.93649994e+02 2.07149994e+02]\n",
      " [2.14779999e+02 2.20199997e+02 2.06899994e+02 2.13070007e+02\n",
      "  2.07369995e+02 2.13070007e+02]]\n",
      "[[1.7588480e+08]\n",
      " [1.0572800e+08]\n",
      " [8.6441600e+07]\n",
      " ...\n",
      " [1.7237330e+08]\n",
      " [1.9813430e+08]\n",
      " [9.6416123e+07]]\n"
     ]
    }
   ],
   "source": [
    "x_df = historical_data[['open', 'prev_high', 'prev_low', 'prev_volume', 'prev_open', 'prev_close']]\n",
    "y_df = historical_data[['Close']] #Target Value to be Specified\n",
    "\n",
    "x = x_df.to_numpy()\n",
    "target = y_df.to_numpy()\n",
    "print(x)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting X to Predict\n",
    "Here, we will gather the most recent information for us to predict. This feature will need to be implemented in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Info Here (We have most_recent to work with previous values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow Models - Regression\n",
    "\n",
    "#### Benchmarking Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into consistent training and testing sets\n",
    "rand_state: int = 42 #Seeding the random state, getting equal splits\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, target, test_size=0.2, random_state=42)\n",
    "def test_model(y_pred):\n",
    "    # start_time = time.time()\n",
    "    # end_time = time.time()\n",
    "    # elasped_time = end_time - start_time\n",
    "    # print(f\"Duration of Execution: {elasped_time} seconds\")\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'R-Squared: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.1002368609756437e+17\n",
      "R-Squared: 0.06351280862250042\n"
     ]
    }
   ],
   "source": [
    "#Fitting/Training the model\n",
    "lg_model = LinearRegression()\n",
    "lg_model.fit(x_train, y_train)\n",
    "#Getting & Evaluating Results\n",
    "y_pred = lg_model.predict(x_test)\n",
    "test_model(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SGD Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_model = SGDRegressor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
